{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import six_layers as model\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import os, sys"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "currentdir = os.path.dirname(os.path.abspath(''))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "grandparentdir = os.path.dirname(parentdir)\n",
    "sys.path.append(grandparentdir)\n",
    "\n",
    "from res.process_data.dataset import tensor_dataset\n",
    "from res.fnn.training import training_bce\n",
    "import res.process_data.process_output as pro_out\n",
    "import res.fnn.functions as func\n",
    "\n",
    "from res.process_data.dataset import tensor_dataset\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dengnaicheng/Developer/intro_GANs/gansForPolymer/Naicheng/res/fnn\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "input_coorinate = np.load('../../data/coordinates.npy')\n",
    "input_three_dirc = np.load('../../data/three_directions.npy')"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "z_dim = 8\n",
    "lr = 0.0001\n",
    "gen = model.GeneratorNet()\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr = lr)\n",
    "disc = model.DiscriminatorNet()\n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr = lr)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "check_point_gen = torch.load('6_layers/model_gan_2000.pth.tar')\n",
    "# check_point_disc = torch.load('6_layers/model_disc_2000.pth.tar')\n",
    "gen.load_state_dict(check_point_gen['gen_state_dict'])\n",
    "# disc.load_state_dict(check_point_disc['disc_state_dict'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "shuffle = True\n",
    "batch_size = 125\n",
    "num_worker = 0\n",
    "pin_memory = True\n",
    "input_tensor = torch.Tensor(input_three_dirc)\n",
    "my_dataset = tensor_dataset(input_tensor, 15, 1)\n",
    "my_dataloader = DataLoader(dataset= my_dataset,\n",
    "                            shuffle=shuffle,\n",
    "                            batch_size=batch_size,\n",
    "                            num_workers=num_worker,\n",
    "                            pin_memory=pin_memory)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from Naicheng.res.fnn.training import training_bce, training_wloss\n",
    "import Naicheng.res.process_data.process_output as pro_out\n",
    "display_step = 782"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import json\n",
    "# 定义一个workflow\n",
    "# 每训练100次，保存模型，保存输出\n",
    "# save all the loss value\n",
    "loss_value_disc = {}\n",
    "loss_value_gen = {}\n",
    "n_critic = 5\n",
    "clip_value = 0.01\n",
    "total_epoch = 2000\n",
    "epoch_step = 100\n",
    "for i in range(10):\n",
    "    pro_out.save_model(gen, disc, 'model', total_epoch)\n",
    "    # disc_loss, gen_loss = training_bce(gen, disc, z_dim, epoch_step, my_dataloader, device, disc_opt, gen_opt,\n",
    "    #              display_step)\n",
    "    training_wloss(gen, disc, my_dataloader, epoch_step, z_dim,\n",
    "                   batch_size, device, disc_opt, gen_opt, n_critic, clip_value)\n",
    "    total_epoch += epoch_step\n",
    "    # loss_value_disc[f'epoch{total_epoch}'] = disc_loss\n",
    "    # loss_value_gen[f'epoch{total_epoch}'] = gen_loss\n",
    "with open('gen_loss.json', 'w') as fp:\n",
    "    json.dump(loss_value_gen, fp)\n",
    "with open('disc_loss.json', 'w') as fp:\n",
    "    json.dump(loss_value_disc, fp)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}